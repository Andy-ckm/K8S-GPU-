# RAG (Retrieval-Augmented Generation) 方案设计

## 1. RAG 概述

### 1.1. 什么是 RAG？
*   **定义**: RAG 是一种将**信息检索 (Retrieval)** 和**文本生成 (Generation)** 相结合的技术框架。它允许大语言模型（LLM）在回答问题或生成文本时，先从外部知识库中检索相关信息，然后将这些信息作为上下文来生成更准确、更可靠的答案。

### 1.2. 为什么需要 RAG？
*   **解决知识截止问题**: （LLM 的知识是静态的，RAG 可以让它访问最新的信息。）
*   **减少幻觉 (Hallucination)**: （通过提供事实依据，降低模型“胡说八道”的概率。）
*   **实现私有知识问答**: （让模型能够基于企业内部的文档、数据库进行回答。）
*   **可解释性与溯源**: （可以追溯答案来源于哪篇文档。）

## 2. RAG 核心流程

![RAG 流程图](https://pica.zhimg.com/v2-a8123165353b4228f43342934f95e4a3_1440w.webp?source=172ae18b "RAG 流程图")
*（图片来源网络，仅为示意）*

### 2.1. 数据索引阶段 (Indexing)
1.  **加载数据 (Load)**: 从各种数据源（PDF, HTML, DB...）加载文档。
2.  **切分文档 (Split)**: 将长文档切分成更小的、语义完整的块 (Chunks)。
3.  **文本嵌入 (Embed)**: 使用嵌入模型（Embedding Model）将每个文本块转换为向量（Vector）。
4.  **存入向量数据库 (Store)**: 将文本块和其对应的向量存入向量数据库（Vector Database）中。

### 2.2. 检索与生成阶段 (Retrieval & Generation)
1.  **用户提问**: 用户输入一个问题 (Query)。
2.  **查询向量化**: 使用同样的嵌入模型将用户问题转换为查询向量。
3.  **向量检索**: 在向量数据库中进行相似度搜索，找出与查询向量最相似的 Top-K 个文本块。
4.  **构建 Prompt**: 将检索到的文本块作为上下文，与原始问题一起组合成一个 Prompt。
5.  **LLM 生成答案**: 将构建好的 Prompt 发送给 LLM，生成最终答案。

## 3. 关键技术选型

| 环节 | 常用工具/模型 | 备注 |
| :--- | :--- | :--- |
| **流程编排框架** | LangChain, LlamaIndex | 提供了 RAG 流程的完整封装 |
| **文档加载器** | LangChain Document Loaders | 支持上百种数据源 |
| **文本切分器** | RecursiveCharacterTextSplitter | 常用且效果不错的切分策略 |
| **嵌入模型** | bge-large-zh, m3e-base | 选择适合中英文场景的开源模型 |
| **向量数据库** | Chroma, FAISS, Milvus, Pinecone | 从内存级到分布式，按需选择 |
| **LLM** | ChatGLM, Qwen, Llama | |

## 4. RAG 优化方向

*   **检索优化**:
    *   **查询重写 (Query Rewriting)**: 使用 LLM 优化或扩展用户的原始问题。
    *   **重排 (Reranking)**: 使用更复杂的交叉编码器模型对初步检索出的结果进行重新排序。
*   **索引优化**:
    *   **多索引策略**: （例如，同时索引文档摘要和完整内容。）
*   **生成优化**:
    *   **Prompt 优化**: （调整上下文在 Prompt 中的位置和格式。）
    *   **模型微调**: （对 LLM 进行微调，使其更擅长利用检索到的上下文。）
